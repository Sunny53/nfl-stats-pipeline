# ğŸˆ NFL Stats ETL Pipeline & Analytics Dashboard

## ğŸ“Š Project Overview

An automated data pipeline that transforms raw NFL statistics into actionable insights through unique performance metrics. This project showcases end-to-end data engineering capabilities including extraction, transformation, storage, automation, and visualization.

### ğŸ¯ What Makes This Different

Instead of displaying standard box scores, this pipeline calculates:

**ğŸ’° Value Metrics:**
- **Points Per Dollar (PPD)**: Player ROI based on salary cap efficiency
- **Snap Efficiency Rating**: Production per opportunity (normalized for playing time)
- **Consistency Score**: Week-to-week reliability using variance analysis

**ğŸ¯ Situational Performance:**
- **Clutch Performance Index**: How players perform under pressure vs. normal situations
- **Momentum Shift Score**: Quantifying game-changing plays and swing events
- **Fatigue Factor Index**: Performance impact of schedule density and travel

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ESPN API        â”‚
â”‚  Salary Data     â”‚â”€â”€â”€â”€â”€â”€â”
â”‚  Weather API     â”‚      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
                          â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Python ETL     â”‚
                   â”‚  - Extract      â”‚
                   â”‚  - Transform    â”‚
                   â”‚  - Calculate    â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  PostgreSQL     â”‚
                   â”‚  (Supabase)     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  GitHub Actions â”‚
                   â”‚  (Daily 6AM ET) â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Power BI       â”‚
                   â”‚  Dashboard      â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Extraction** | Python 3.11, Requests | API integration, data fetching |
| **Transformation** | Pandas, NumPy | Data cleaning, metric calculation |
| **Storage** | PostgreSQL 15, SQLAlchemy | Normalized relational database |
| **Orchestration** | GitHub Actions | Automated daily pipeline execution |
| **Visualization** | Power BI Desktop | Interactive dashboards |
| **Hosting** | Supabase (DB), GitHub, Power BI Service | Cloud infrastructure |

## ğŸ“ Project Structure

```
nfl-stats-pipeline/
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ etl_pipeline.yml          # Automation workflow
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                     # Configuration management
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ connection.py             # Database connection pooling
â”‚   â”‚   â”œâ”€â”€ models.py                 # SQLAlchemy ORM models
â”‚   â”‚   â””â”€â”€ schema.sql                # Database schema DDL
â”‚   â”‚
â”‚   â”œâ”€â”€ extraction/
â”‚   â”‚   â”œâ”€â”€ api_client.py             # ESPN API wrapper
â”‚   â”‚   â”œâ”€â”€ extractors.py             # Data fetching orchestration
â”‚   â”‚   â””â”€â”€ salary_scraper.py         # Salary cap data collection
â”‚   â”‚
â”‚   â”œâ”€â”€ transformation/
â”‚   â”‚   â”œâ”€â”€ cleaners.py               # Data cleaning & validation
â”‚   â”‚   â”œâ”€â”€ value_metrics.py          # PPD, Snap Efficiency, Consistency
â”‚   â”‚   â””â”€â”€ situational_metrics.py    # Clutch, Momentum, Fatigue
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.py                 # Structured logging
â”‚       â””â”€â”€ helpers.py                # Utility functions
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_etl.py                    # Main ETL orchestrator
â”‚   â”œâ”€â”€ setup_db.py                   # Database initialization
â”‚   â””â”€â”€ backfill_historical.py        # Historical data loader
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_extraction.py
â”‚   â”œâ”€â”€ test_transformation.py
â”‚   â””â”€â”€ test_metrics.py
â”‚
â”œâ”€â”€ dashboards/
â”‚   â””â”€â”€ nfl_analytics.pbix            # Power BI dashboard file
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ metric_validation.ipynb       # Metric testing & validation
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- PostgreSQL 15+ (or Supabase account)
- Power BI Desktop
- Git

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/nfl-stats-pipeline.git
cd nfl-stats-pipeline
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure environment variables**
```bash
cp .env.example .env
# Edit .env with your database credentials
```

5. **Initialize database**
```bash
python scripts/setup_db.py
```

6. **Run initial ETL**
```bash
python scripts/run_etl.py
```

## ğŸ“Š Sample Insights

*[Will be populated after dashboard creation]*

- **Most Undervalued Player**: [Player Name] with PPD of X (producing elite stats at rookie contract)
- **Clutch King**: [Player Name] performs 35% better in high-pressure situations
- **Consistency Leader**: [Team Name] has lowest variance in weekly performance (ideal playoff team)

## ğŸ”„ Automation

The pipeline runs automatically:
- **Schedule**: Daily at 6:00 AM EST
- **Trigger**: GitHub Actions workflow
- **Duration**: ~5-8 minutes per run
- **Notifications**: Errors logged to GitHub Actions

Manual trigger available via GitHub Actions UI.

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/

# Run specific test suite
pytest tests/test_metrics.py -v

# Check code coverage
pytest --cov=src tests/
```

## ğŸ“ˆ Unique Metrics Explained

### Value Metrics ğŸ’°

**Points Per Dollar (PPD)**
```
PPD = Player's Expected Points Added (EPA) / Annual Salary (in millions)
```
Identifies undervalued players who maximize production relative to cost.

**Snap Efficiency Rating**
```
Snap Efficiency = (Total Production Score) / (% of Team Snaps Played)
```
Reveals high-impact players with limited opportunities.

**Consistency Score**
```
Consistency = 100 - (Coefficient of Variation Ã— 100)
CV = (Std Dev / Mean) Ã— 100
```
Measures week-to-week reliability (critical for playoffs).

### Situational Metrics ğŸ¯

**Clutch Performance Index (CPI)**
```
CPI = (Success Rate in Clutch Situations / Overall Success Rate) Ã— 100
```
Clutch = 4th quarter, within 7 points, or critical 3rd/4th downs.

**Momentum Shift Score**
Weighted sum of swing events (turnovers, goal-line stands, 4th down conversions).

**Fatigue Factor Index**
Performance degradation based on rest days, travel distance, and injury load.

## ğŸ”® Future Enhancements

- [ ] Schedule-Adjusted Performance (normalize for opponent strength)
- [ ] Machine learning predictions for playoff outcomes
- [ ] Real-time streaming data integration
- [ ] REST API for external consumption
- [ ] Sentiment analysis from social media

## ğŸ“ Data Sources

- **Game Stats**: ESPN API (unofficial endpoints)
- **Historical Data**: nfl-data-py library
- **Salary Data**: OverTheCap.com / Spotrac
- **Weather Data**: OpenWeatherMap API

## ğŸ“ What I Learned

- Building production-grade ETL pipelines with error handling
- Designing normalized database schemas for analytics
- Implementing custom statistical metrics from domain research
- Orchestrating automated workflows with GitHub Actions
- Creating business-focused dashboards that tell stories

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ¤ Connect

**[Your Name]**
- LinkedIn: [Your LinkedIn]
- Email: [Your Email]
- Portfolio: [Your Website]

---

*This project demonstrates end-to-end data engineering skills including API integration, data transformation, database design, automation, and business intelligence visualization.*
